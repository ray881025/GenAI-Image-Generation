import torch
from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler
import random
import numpy as np
from PIL import Image, ImageDraw
import os

class StableDiffusionGenerator:
    def __init__(self, model_id="CompVis/stable-diffusion-v1-4"):
        """
        Initialize the Stable Diffusion generator with the specified model.
        
        Args:
            model_id (str): The Hugging Face model ID for Stable Diffusion
        """
        self.model_id = model_id
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"Using device: {self.device}")
        
        # Load the pipeline
        self.pipeline = StableDiffusionPipeline.from_pretrained(
            model_id,
            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
            safety_checker=None  # For demonstration purposes only
        )
        
        # Use the DPMSolver++ scheduler for faster inference
        self.pipeline.scheduler = DPMSolverMultistepScheduler.from_config(
            self.pipeline.scheduler.config
        )
        
        # Move the pipeline to the device
        self.pipeline = self.pipeline.to(self.device)
        
        # Enable memory efficient attention if using CUDA
        if self.device == "cuda":
            self.pipeline.enable_attention_slicing()
    
    def generate_image(self, output_path, prompt, negative_prompt=None, 
                      num_inference_steps=10, guidance_scale=7.5,
                      width=512, height=512, seed=None):
        """
        Generate an image based on the provided prompt and parameters.
        
        Args:
            output_path (str): Path to save the generated image
            prompt (str): Text prompt for image generation
            negative_prompt (str, optional): Negative prompt to guide what not to generate
            num_inference_steps (int): Number of denoising steps (more = higher quality, slower)
            guidance_scale (float): How closely to follow the prompt (higher = more faithful)
            width (int): Width of the generated image
            height (int): Height of the generated image
            seed (int, optional): Random seed for reproducibility
            
        Returns:
            str: Path to the generated image
        """
        # Set the random seed if provided
        if seed is not None:
            torch.manual_seed(seed)
            np.random.seed(seed)
            random.seed(seed)
        else:
            # Generate a random seed
            seed = random.randint(0, 2147483647)
            torch.manual_seed(seed)
            np.random.seed(seed)
            random.seed(seed)
        
        # Clamp width/height to be divisible by 8 (requirement)
        width = (width // 8) * 8 if width else 256
        height = (height // 8) * 8 if height else 256
        num_inference_steps = min(num_inference_steps or 50, 15)
        guidance_scale = min(guidance_scale or 7.5, 7.5)

        print("[GENERATOR] Running Stable Diffusion pipeline...")

        try:
            result = self.pipeline(
                prompt=prompt,
                negative_prompt=negative_prompt,
                num_inference_steps=num_inference_steps,
                guidance_scale=guidance_scale,
                width=width,
                height=height
            )
            image = result.images[0]
            print("[GENERATOR] ✅ Image generated by model.")
        except Exception as e:
            print(f"[GENERATOR] ❌ Error during pipeline generation: {e}")
            raise e


        # Save the image
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        image.save(output_path)
        
        return output_path
    
    def unload(self):
        """
        Unload the model from GPU memory when not in use.
        """
        if self.device == "cuda":
            self.pipeline = self.pipeline.to("cpu")
            torch.cuda.empty_cache()
            print("Model unloaded from GPU")